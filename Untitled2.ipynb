{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNn1duVXCdo2Px0JxLmJRuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoderRdm/CoderRdm/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "leetcode_profiles = [\n",
        "    \"https://leetcode.com/Divyansh_Joshi_MNIT/\",\n",
        "    \"https://leetcode.com/Dhruv_parashar673/\",\n",
        "    \"https://leetcode.com/shivansh_codes/\",\n",
        "    \"https://leetcode.com/hardik7427/\",\n",
        "    \"https://leetcode.com/Nayu_1501/\",\n",
        "    \"https://leetcode.com/mayank_kumar123/\",\n",
        "    \"https://leetcode.com/tushardhakad355/\",\n",
        "    \"https://leetcode.com/rajatkhedar123/\",\n",
        "    \"https://leetcode.com/Dishank_Jha/\",\n",
        "    \"https://leetcode.com/Khushal_Saini/\",\n",
        "    \"https://leetcode.com/mauliksidana09/\",\n",
        "    \"https://leetcode.com/rudra_singh_07/\",\n",
        "    \"https://leetcode.com/govindsingh_777/\",\n",
        "    \"https://leetcode.com/Vinay-Gupta/\",\n",
        "    \"https://leetcode.com/Shivam_goyal_/\",\n",
        "    \"https://leetcode.com/padmesh_0150/\",\n",
        "    \"https://leetcode.com/Gaurav_1810/\",\n",
        "    \"https://leetcode.com/likhitd/\",\n",
        "    \"https://leetcode.com/Divyanshverma15/\",\n",
        "    \"https://leetcode.com/kushagras_94/\",\n",
        "    \"https://leetcode.com/harshit3458/\",\n",
        "    \"https://leetcode.com/RachitMittal1634/\",\n",
        "    \"https://leetcode.com/saurabh_32/\",\n",
        "    \"https://leetcode.com/tehseen1639/\",\n",
        "    \"https://leetcode.com/ruchika_yadav/\",\n",
        "    \"https://leetcode.com/yugsarda/\",\n",
        "    \"https://leetcode.com/Kartik_Mahnot/\",\n",
        "    \"https://leetcode.com/ViNiT-72/\",\n",
        "    \"https://leetcode.com/RK_Patel/\",\n",
        "    \"https://leetcode.com/beingKashvi/\",\n",
        "    \"https://leetcode.com/vikas_singh_856/\",\n",
        "    \"https://leetcode.com/user2633T/\",\n",
        "    \"https://leetcode.com/ShourayaKaushik/\",\n",
        "    \"https://leetcode.com/jatin-agrawal/\",\n",
        "    \"https://leetcode.com/Bot-Netizen-Programmers/\",\n",
        "    \"https://leetcode.com/bhargav-1673/\",\n",
        "    \"https://leetcode.com/Lakshit_Ramani/\",\n",
        "    \"https://leetcode.com/dhakad_09/\",\n",
        "    \"https://leetcode.com/NAregarded/\",\n",
        "    \"https://leetcode.com/akshaypal_bishnoi/\",\n",
        "    \"https://leetcode.com/godika_priya/\",\n",
        "    \"https://leetcode.com/Tush1586/\",\n",
        "    \"https://leetcode.com/Sarvesh25/\",\n",
        "    \"https://leetcode.com/user8201yw/\",\n",
        "    \"https://leetcode.com/Swayam_141/\",\n",
        "    \"https://leetcode.com/Kashishgarg_15/\",\n",
        "    \"https://leetcode.com/princimantri_2990/\",\n",
        "    \"https://leetcode.com/ankit4092004_Ankit___/\",\n",
        "    \"https://leetcode.com/pritamzzziscodingpranav_1686/\",\n",
        "    \"https://leetcode.com/Dhruvik_MYI/\",\n",
        "    \"https://leetcode.com/pankaj1213/\",\n",
        "    \"https://leetcode.com/kavya1502_/\",\n",
        "    \"https://leetcode.com/suhaani17/\",\n",
        "    \"https://leetcode.com/Dikshit_Rao/\",\n",
        "    \"https://leetcode.com/krishnasharma1234/\",\n",
        "    \"https://leetcode.com/KRITI_BHATNAGAR/\",\n",
        "    \"https://leetcode.com/Roshan_nama12/\",\n",
        "    \"https://leetcode.com/gautam_chauhan04/\",\n",
        "    \"https://leetcode.com/ayushkumar85371/\",\n",
        "    \"https://leetcode.com/Gulab_Rana/\",\n",
        "    \"https://leetcode.com/utkarshmodi10/\",\n",
        "    \"https://leetcode.com/Yash_07___077/\",\n",
        "    \"https://leetcode.com/MJ_Champ/\",\n",
        "    \"https://leetcode.com/AyushTak/\",\n",
        "    \"https://leetcode.com/SIY7gDUBSu/\"\n",
        "]\n",
        "\n",
        "# Function to scrape summary data\n",
        "def scrape_profile(url):\n",
        "    username = url.strip(\"/\").split(\"/\")[-1]\n",
        "    api_url = f\"https://leetcode-stats-api.herokuapp.com/{username}\"  # Free unofficial API\n",
        "\n",
        "    try:\n",
        "        res = requests.get(api_url).json()\n",
        "        return {\n",
        "            \"Username\": username,\n",
        "            \"Total Problems Solved\": res.get(\"totalSolved\", \"N/A\"),\n",
        "            \"Easy\": res.get(\"easySolved\", \"N/A\"),\n",
        "            \"Medium\": res.get(\"mediumSolved\", \"N/A\"),\n",
        "            \"Hard\": res.get(\"hardSolved\", \"N/A\"),\n",
        "            \"Contest Rating\": res.get(\"contestRating\", \"N/A\"),\n",
        "            \"Contests Attended\": res.get(\"contestAttend\", \"N/A\")\n",
        "        }\n",
        "    except:\n",
        "        return {\"Username\": username, \"Error\": \"Could not fetch\"}\n",
        "\n",
        "# Collect all profiles\n",
        "data = [scrape_profile(url) for url in leetcode_profiles]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save as PDF\n",
        "def export_to_pdf(df, filename=\"leetcode_report.pdf\"):\n",
        "    doc = SimpleDocTemplate(filename, pagesize=A4)\n",
        "    elements = []\n",
        "    styles = getSampleStyleSheet()\n",
        "\n",
        "    elements.append(Paragraph(\"LeetCode Leaderboard Report\", styles['Title']))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    # Convert dataframe to table\n",
        "    table_data = [df.columns.tolist()] + df.values.tolist()\n",
        "    table = Table(table_data, repeatRows=1)\n",
        "    table.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.grey),\n",
        "        (\"TEXTCOLOR\",(0,0),(-1,0),colors.whitesmoke),\n",
        "        (\"ALIGN\",(0,0),(-1,-1),\"CENTER\"),\n",
        "        (\"GRID\", (0,0), (-1,-1), 0.5, colors.black),\n",
        "        (\"FONTSIZE\", (0,0), (-1,-1), 8),\n",
        "    ]))\n",
        "\n",
        "    elements.append(table)\n",
        "    doc.build(elements)\n",
        "\n",
        "export_to_pdf(df)\n",
        "print(\"âœ… PDF generated successfully: leetcode_report.pdf\")\n",
        "files.download(\"leetcode_report.pdf\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XXrwbTDfR0r0",
        "outputId": "273749e0-2b05-4240-b1f7-e5054242d5e8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.3)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "    req = Requirement(req_string.strip())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/requirements.py\", line 36, in __init__\n",
            "    parsed = _parse_requirement(requirement_string)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/_parser.py\", line 62, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/_tokenizer.py\", line 105, in __init__\n",
            "    name: re.compile(pattern) for name, pattern in rules.items()\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 1674, in print\n",
            "    renderables = self._collect_renderables(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 1535, in _collect_renderables\n",
            "    renderable = rich_cast(renderable)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/protocol.py\", line 19, in rich_cast\n",
            "    def rich_cast(renderable: object) -> \"RenderableType\":\n",
            "    \n",
            "KeyboardInterrupt\n",
            "^C\n",
            "âœ… PDF generated successfully: leetcode_report.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6f9bb243-5ab5-4bbf-a102-ebadd39ca9d7\", \"leetcode_report.pdf\", 6514)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab requests pandas beautifulsoup4\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from google.colab import files\n",
        "\n",
        "leetcode_profiles = [\n",
        "    \"https://leetcode.com/Divyansh_Joshi_MNIT/\",\n",
        "    \"https://leetcode.com/Dhruv_parashar673/\",\n",
        "    \"https://leetcode.com/shivansh_codes/\",\n",
        "    \"https://leetcode.com/hardik7427/\",\n",
        "    \"https://leetcode.com/Nayu_1501/\"\n",
        "]\n",
        "\n",
        "def scrape_profile_multiple_apis(url):\n",
        "    \"\"\"Try multiple APIs and methods for better reliability\"\"\"\n",
        "    username = url.strip(\"/\").split(\"/\")[-1]\n",
        "\n",
        "    # Method 1: Try the original API\n",
        "    try:\n",
        "        api_url = f\"https://leetcode-stats-api.herokuapp.com/{username}\"\n",
        "        response = requests.get(api_url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            res = response.json()\n",
        "            if 'status' not in res or res.get('status') != 'error':\n",
        "                return {\n",
        "                    \"Username\": username,\n",
        "                    \"Total Problems Solved\": res.get(\"totalSolved\", 0),\n",
        "                    \"Easy\": res.get(\"easySolved\", 0),\n",
        "                    \"Medium\": res.get(\"mediumSolved\", 0),\n",
        "                    \"Hard\": res.get(\"hardSolved\", 0),\n",
        "                    \"Contest Rating\": res.get(\"contestRating\", 0),\n",
        "                    \"Contests Attended\": res.get(\"contestAttend\", 0),\n",
        "                    \"Status\": \"Success (API 1)\"\n",
        "                }\n",
        "    except Exception as e:\n",
        "        print(f\"API 1 failed for {username}: {e}\")\n",
        "\n",
        "    # Method 2: Try alternative API\n",
        "    try:\n",
        "        api_url2 = f\"https://alfa-leetcode-api.onrender.com/{username}/solved\"\n",
        "        response = requests.get(api_url2, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            res = response.json()\n",
        "            return {\n",
        "                \"Username\": username,\n",
        "                \"Total Problems Solved\": res.get(\"solvedProblem\", 0),\n",
        "                \"Easy\": res.get(\"easySolved\", 0),\n",
        "                \"Medium\": res.get(\"mediumSolved\", 0),\n",
        "                \"Hard\": res.get(\"hardSolved\", 0),\n",
        "                \"Contest Rating\": \"N/A\",  # This API might not have contest data\n",
        "                \"Contests Attended\": \"N/A\",\n",
        "                \"Status\": \"Success (API 2)\"\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"API 2 failed for {username}: {e}\")\n",
        "\n",
        "    # Method 3: Try web scraping (basic attempt)\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            # This is a basic attempt - LeetCode's structure may change\n",
        "            # Look for common patterns in the HTML\n",
        "            return {\n",
        "                \"Username\": username,\n",
        "                \"Total Problems Solved\": \"Scraping Error\",\n",
        "                \"Easy\": \"Scraping Error\",\n",
        "                \"Medium\": \"Scraping Error\",\n",
        "                \"Hard\": \"Scraping Error\",\n",
        "                \"Contest Rating\": \"Scraping Error\",\n",
        "                \"Contests Attended\": \"Scraping Error\",\n",
        "                \"Status\": \"Scraping Attempted\"\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"Web scraping failed for {username}: {e}\")\n",
        "\n",
        "    # If all methods fail\n",
        "    return {\n",
        "        \"Username\": username,\n",
        "        \"Total Problems Solved\": \"Failed\",\n",
        "        \"Easy\": \"Failed\",\n",
        "        \"Medium\": \"Failed\",\n",
        "        \"Hard\": \"Failed\",\n",
        "        \"Contest Rating\": \"Failed\",\n",
        "        \"Contests Attended\": \"Failed\",\n",
        "        \"Status\": \"All methods failed\"\n",
        "    }\n",
        "\n",
        "def scrape_all_profiles(profiles):\n",
        "    \"\"\"Scrape all profiles with progress tracking and rate limiting\"\"\"\n",
        "    data = []\n",
        "    total = len(profiles)\n",
        "\n",
        "    for i, url in enumerate(profiles, 1):\n",
        "        print(f\"Processing {i}/{total}: {url.split('/')[-2]}\")\n",
        "        result = scrape_profile_multiple_apis(url)\n",
        "        data.append(result)\n",
        "\n",
        "        # Rate limiting - wait between requests\n",
        "        time.sleep(1)  # 1 second delay between requests\n",
        "\n",
        "        # Show progress every 10 profiles\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Completed {i}/{total} profiles\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def export_to_pdf(df, filename=\"leetcode_report.pdf\"):\n",
        "    \"\"\"Export DataFrame to PDF with improved formatting\"\"\"\n",
        "    doc = SimpleDocTemplate(filename, pagesize=A4)\n",
        "    elements = []\n",
        "    styles = getSampleStyleSheet()\n",
        "\n",
        "    # Title\n",
        "    elements.append(Paragraph(\"LeetCode Leaderboard Report\", styles['Title']))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    # Summary statistics\n",
        "    total_users = len(df)\n",
        "    successful_scrapes = len(df[df['Status'].str.contains('Success', na=False)])\n",
        "\n",
        "    summary_text = f\"\"\"\n",
        "    <b>Summary:</b><br/>\n",
        "    Total Users: {total_users}<br/>\n",
        "    Successfully Scraped: {successful_scrapes}<br/>\n",
        "    Success Rate: {successful_scrapes/total_users*100:.1f}%\n",
        "    \"\"\"\n",
        "    elements.append(Paragraph(summary_text, styles['Normal']))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    # Create table without the Status column for cleaner output\n",
        "    display_df = df.drop('Status', axis=1, errors='ignore')\n",
        "    table_data = [display_df.columns.tolist()] + display_df.values.tolist()\n",
        "\n",
        "    table = Table(table_data, repeatRows=1)\n",
        "    table.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.grey),\n",
        "        (\"TEXTCOLOR\",(0,0),(-1,0),colors.whitesmoke),\n",
        "        (\"ALIGN\",(0,0),(-1,-1),\"CENTER\"),\n",
        "        (\"GRID\", (0,0), (-1,-1), 0.5, colors.black),\n",
        "        (\"FONTSIZE\", (0,0), (-1,-1), 7),\n",
        "        (\"VALIGN\", (0,0), (-1,-1), \"MIDDLE\"),\n",
        "    ]))\n",
        "\n",
        "    elements.append(table)\n",
        "    doc.build(elements)\n",
        "\n",
        "# Main execution\n",
        "print(\"Starting LeetCode profile scraping...\")\n",
        "print(\"This may take a while due to rate limiting...\")\n",
        "\n",
        "# Collect all profiles\n",
        "data = scrape_all_profiles(leetcode_profiles)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Show summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SCRAPING SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total profiles processed: {len(df)}\")\n",
        "print(f\"Successful scrapes: {len(df[df['Status'].str.contains('Success', na=False)])}\")\n",
        "print(f\"Failed scrapes: {len(df[df['Status'].str.contains('Failed', na=False)])}\")\n",
        "\n",
        "# Show status breakdown\n",
        "print(\"\\nStatus breakdown:\")\n",
        "print(df['Status'].value_counts())\n",
        "\n",
        "# Display first few rows for verification\n",
        "print(\"\\nFirst 5 results:\")\n",
        "print(df.head().to_string())\n",
        "\n",
        "# Save as CSV for backup\n",
        "df.to_csv('leetcode_data_backup.csv', index=False)\n",
        "print(\"\\nâœ… Data backed up to CSV: leetcode_data_backup.csv\")\n",
        "\n",
        "# Export to PDF\n",
        "export_to_pdf(df)\n",
        "print(\"âœ… PDF generated successfully: leetcode_report.pdf\")\n",
        "\n",
        "# Download files\n",
        "files.download(\"leetcode_report.pdf\")\n",
        "files.download(\"leetcode_data_backup.csv\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ Process completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "NM_mT760cPB7",
        "outputId": "2592ee08-4661-4275-abe3-c36c4ac506f7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Starting LeetCode profile scraping...\n",
            "This may take a while due to rate limiting...\n",
            "Processing 1/5: Divyansh_Joshi_MNIT\n",
            "Processing 2/5: Dhruv_parashar673\n",
            "Processing 3/5: shivansh_codes\n",
            "Processing 4/5: hardik7427\n",
            "Processing 5/5: Nayu_1501\n",
            "\n",
            "==================================================\n",
            "SCRAPING SUMMARY\n",
            "==================================================\n",
            "Total profiles processed: 5\n",
            "Successful scrapes: 5\n",
            "Failed scrapes: 0\n",
            "\n",
            "Status breakdown:\n",
            "Status\n",
            "Success (API 1)    5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "First 5 results:\n",
            "              Username  Total Problems Solved  Easy  Medium  Hard  Contest Rating  Contests Attended           Status\n",
            "0  Divyansh_Joshi_MNIT                    675   183     402    90               0                  0  Success (API 1)\n",
            "1    Dhruv_parashar673                    395   147     215    33               0                  0  Success (API 1)\n",
            "2       shivansh_codes                    233    79     131    23               0                  0  Success (API 1)\n",
            "3           hardik7427                    413   105     263    45               0                  0  Success (API 1)\n",
            "4            Nayu_1501                    143    58      70    15               0                  0  Success (API 1)\n",
            "\n",
            "âœ… Data backed up to CSV: leetcode_data_backup.csv\n",
            "âœ… PDF generated successfully: leetcode_report.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_930a7315-ca21-43be-a164-5a95abc026ea\", \"leetcode_report.pdf\", 2461)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7c4e1361-9f2a-4ca8-a8f1-ae29148d7586\", \"leetcode_data_backup.csv\", 334)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ‰ Process completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab requests pandas beautifulsoup4 selenium\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from google.colab import files\n",
        "import json\n",
        "from urllib.parse import quote\n",
        "\n",
        "leetcode_profiles = [\n",
        "    \"https://leetcode.com/Divyansh_Joshi_MNIT/\",\n",
        "    \"https://leetcode.com/Dhruv_parashar673/\",\n",
        "    \"https://leetcode.com/shivansh_codes/\",\n",
        "    \"https://leetcode.com/hardik7427/\",\n",
        "    \"https://leetcode.com/Nayu_1501/\",\n",
        "    \"https://leetcode.com/mayank_kumar123/\",\n",
        "    \"https://leetcode.com/tushardhakad355/\",\n",
        "    \"https://leetcode.com/rajatkhedar123/\",\n",
        "    \"https://leetcode.com/Dishank_Jha/\",\n",
        "    \"https://leetcode.com/Khushal_Saini/\",\n",
        "    \"https://leetcode.com/mauliksidana09/\",\n",
        "    \"https://leetcode.com/rudra_singh_07/\",\n",
        "    \"https://leetcode.com/govindsingh_777/\",\n",
        "    \"https://leetcode.com/Vinay-Gupta/\",\n",
        "    \"https://leetcode.com/Shivam_goyal_/\",\n",
        "    \"https://leetcode.com/padmesh_0150/\",\n",
        "    \"https://leetcode.com/Gaurav_1810/\",\n",
        "    \"https://leetcode.com/likhitd/\",\n",
        "    \"https://leetcode.com/Divyanshverma15/\",\n",
        "    \"https://leetcode.com/kushagras_94/\",\n",
        "    \"https://leetcode.com/harshit3458/\",\n",
        "    \"https://leetcode.com/RachitMittal1634/\",\n",
        "    \"https://leetcode.com/saurabh_32/\",\n",
        "    \"https://leetcode.com/tehseen1639/\",\n",
        "    \"https://leetcode.com/ruchika_yadav/\",\n",
        "    \"https://leetcode.com/yugsarda/\",\n",
        "    \"https://leetcode.com/Kartik_Mahnot/\",\n",
        "    \"https://leetcode.com/ViNiT-72/\",\n",
        "    \"https://leetcode.com/RK_Patel/\",\n",
        "    \"https://leetcode.com/beingKashvi/\",\n",
        "    \"https://leetcode.com/vikas_singh_856/\",\n",
        "    \"https://leetcode.com/user2633T/\",\n",
        "    \"https://leetcode.com/ShourayaKaushik/\",\n",
        "    \"https://leetcode.com/jatin-agrawal/\",\n",
        "    \"https://leetcode.com/Bot-Netizen-Programmers/\",\n",
        "    \"https://leetcode.com/bhargav-1673/\",\n",
        "    \"https://leetcode.com/Lakshit_Ramani/\",\n",
        "    \"https://leetcode.com/dhakad_09/\",\n",
        "    \"https://leetcode.com/NAregarded/\",\n",
        "    \"https://leetcode.com/akshaypal_bishnoi/\",\n",
        "    \"https://leetcode.com/godika_priya/\",\n",
        "    \"https://leetcode.com/Tush1586/\",\n",
        "    \"https://leetcode.com/Sarvesh25/\",\n",
        "    \"https://leetcode.com/user8201yw/\",\n",
        "    \"https://leetcode.com/Swayam_141/\",\n",
        "    \"https://leetcode.com/Kashishgarg_15/\",\n",
        "    \"https://leetcode.com/princimantri_2990/\",\n",
        "    \"https://leetcode.com/ankit4092004_Ankit___/\",\n",
        "    \"https://leetcode.com/pritamzzziscodingpranav_1686/\",\n",
        "    \"https://leetcode.com/Dhruvik_MYI/\",\n",
        "    \"https://leetcode.com/pankaj1213/\",\n",
        "    \"https://leetcode.com/kavya1502_/\",\n",
        "    \"https://leetcode.com/suhaani17/\",\n",
        "    \"https://leetcode.com/Dikshit_Rao/\",\n",
        "    \"https://leetcode.com/krishnasharma1234/\",\n",
        "    \"https://leetcode.com/KRITI_BHATNAGAR/\",\n",
        "    \"https://leetcode.com/Roshan_nama12/\",\n",
        "    \"https://leetcode.com/gautam_chauhan04/\",\n",
        "    \"https://leetcode.com/ayushkumar85371/\",\n",
        "    \"https://leetcode.com/Gulab_Rana/\",\n",
        "    \"https://leetcode.com/utkarshmodi10/\",\n",
        "    \"https://leetcode.com/Yash_07___077/\",\n",
        "    \"https://leetcode.com/MJ_Champ/\",\n",
        "    \"https://leetcode.com/AyushTak/\",\n",
        "    \"https://leetcode.com/SIY7gDUBSu/\"\n",
        "]\n",
        "\n",
        "class LeetCodeScraper:\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "            'Accept-Language': 'en-US,en;q=0.5',\n",
        "            'Accept-Encoding': 'gzip, deflate, br',\n",
        "            'DNT': '1',\n",
        "            'Connection': 'keep-alive',\n",
        "            'Upgrade-Insecure-Requests': '1',\n",
        "        })\n",
        "\n",
        "    def extract_from_script_tags(self, soup, username):\n",
        "        \"\"\"Extract data from JavaScript variables in script tags\"\"\"\n",
        "        script_tags = soup.find_all('script')\n",
        "\n",
        "        for script in script_tags:\n",
        "            if script.string:\n",
        "                content = script.string\n",
        "\n",
        "                # Look for JSON data patterns\n",
        "                if 'submissionList' in content or 'contestBadge' in content:\n",
        "                    try:\n",
        "                        # Extract JSON-like data using regex\n",
        "                        json_match = re.search(r'(\\{.*\\})', content)\n",
        "                        if json_match:\n",
        "                            # This would need more specific parsing\n",
        "                            pass\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "        return {}\n",
        "\n",
        "    def scrape_with_graphql(self, username):\n",
        "        \"\"\"Try to use LeetCode's GraphQL API\"\"\"\n",
        "        try:\n",
        "            graphql_url = \"https://leetcode.com/graphql/\"\n",
        "\n",
        "            # Query for user profile\n",
        "            query = \"\"\"\n",
        "            query getUserProfile($username: String!) {\n",
        "                matchedUser(username: $username) {\n",
        "                    username\n",
        "                    submitStats {\n",
        "                        acSubmissionNum {\n",
        "                            difficulty\n",
        "                            count\n",
        "                        }\n",
        "                    }\n",
        "                    profile {\n",
        "                        ranking\n",
        "                        userAvatar\n",
        "                        realName\n",
        "                    }\n",
        "                }\n",
        "                userContestRanking(username: $username) {\n",
        "                    attendedContestsCount\n",
        "                    rating\n",
        "                    globalRanking\n",
        "                    totalParticipants\n",
        "                }\n",
        "            }\n",
        "            \"\"\"\n",
        "\n",
        "            payload = {\n",
        "                'query': query,\n",
        "                'variables': {'username': username}\n",
        "            }\n",
        "\n",
        "            response = self.session.post(graphql_url, json=payload, timeout=15)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "\n",
        "                if 'data' in data and data['data'].get('matchedUser'):\n",
        "                    user_data = data['data']['matchedUser']\n",
        "                    contest_data = data['data'].get('userContestRanking', {})\n",
        "\n",
        "                    # Parse submission stats\n",
        "                    easy = medium = hard = 0\n",
        "                    if user_data.get('submitStats', {}).get('acSubmissionNum'):\n",
        "                        for stat in user_data['submitStats']['acSubmissionNum']:\n",
        "                            if stat['difficulty'] == 'Easy':\n",
        "                                easy = stat['count']\n",
        "                            elif stat['difficulty'] == 'Medium':\n",
        "                                medium = stat['count']\n",
        "                            elif stat['difficulty'] == 'Hard':\n",
        "                                hard = stat['count']\n",
        "\n",
        "                    return {\n",
        "                        \"Username\": username,\n",
        "                        \"Total Problems Solved\": easy + medium + hard,\n",
        "                        \"Easy\": easy,\n",
        "                        \"Medium\": medium,\n",
        "                        \"Hard\": hard,\n",
        "                        \"Contest Rating\": contest_data.get('rating', 0) if contest_data else 0,\n",
        "                        \"Contests Attended\": contest_data.get('attendedContestsCount', 0) if contest_data else 0,\n",
        "                        \"Global Ranking\": contest_data.get('globalRanking', 'N/A') if contest_data else 'N/A',\n",
        "                        \"Status\": \"Success (GraphQL)\"\n",
        "                    }\n",
        "        except Exception as e:\n",
        "            print(f\"GraphQL failed for {username}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def scrape_direct_html(self, username, url):\n",
        "        \"\"\"Direct HTML scraping with improved parsing\"\"\"\n",
        "        try:\n",
        "            response = self.session.get(url, timeout=15)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "                # Initialize default values\n",
        "                result = {\n",
        "                    \"Username\": username,\n",
        "                    \"Total Problems Solved\": 0,\n",
        "                    \"Easy\": 0,\n",
        "                    \"Medium\": 0,\n",
        "                    \"Hard\": 0,\n",
        "                    \"Contest Rating\": 0,\n",
        "                    \"Contests Attended\": 0,\n",
        "                    \"Global Ranking\": 'N/A',\n",
        "                    \"Status\": \"HTML Scraping\"\n",
        "                }\n",
        "\n",
        "                # Look for problem stats in various possible locations\n",
        "                # Method 1: Look for text patterns\n",
        "                text_content = soup.get_text()\n",
        "\n",
        "                # Extract numbers followed by \"Solved\" or similar patterns\n",
        "                solved_pattern = re.search(r'(\\d+)\\s*(?:Problems?\\s*)?Solved', text_content, re.IGNORECASE)\n",
        "                if solved_pattern:\n",
        "                    result[\"Total Problems Solved\"] = int(solved_pattern.group(1))\n",
        "\n",
        "                # Look for difficulty breakdowns\n",
        "                easy_pattern = re.search(r'Easy\\s*[:\\-]?\\s*(\\d+)', text_content, re.IGNORECASE)\n",
        "                if easy_pattern:\n",
        "                    result[\"Easy\"] = int(easy_pattern.group(1))\n",
        "\n",
        "                medium_pattern = re.search(r'Medium\\s*[:\\-]?\\s*(\\d+)', text_content, re.IGNORECASE)\n",
        "                if medium_pattern:\n",
        "                    result[\"Medium\"] = int(medium_pattern.group(1))\n",
        "\n",
        "                hard_pattern = re.search(r'Hard\\s*[:\\-]?\\s*(\\d+)', text_content, re.IGNORECASE)\n",
        "                if hard_pattern:\n",
        "                    result[\"Hard\"] = int(hard_pattern.group(1))\n",
        "\n",
        "                # Look for contest rating\n",
        "                rating_pattern = re.search(r'Rating\\s*[:\\-]?\\s*(\\d+)', text_content, re.IGNORECASE)\n",
        "                if rating_pattern:\n",
        "                    result[\"Contest Rating\"] = int(rating_pattern.group(1))\n",
        "\n",
        "                # Look for contests attended\n",
        "                contests_pattern = re.search(r'Attended\\s*[:\\-]?\\s*(\\d+)', text_content, re.IGNORECASE)\n",
        "                if contests_pattern:\n",
        "                    result[\"Contests Attended\"] = int(contests_pattern.group(1))\n",
        "\n",
        "                # Method 2: Look in script tags for JSON data\n",
        "                script_data = self.extract_from_script_tags(soup, username)\n",
        "                if script_data:\n",
        "                    result.update(script_data)\n",
        "\n",
        "                return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"HTML scraping failed for {username}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def try_multiple_apis(self, username):\n",
        "        \"\"\"Try multiple third-party APIs\"\"\"\n",
        "        apis = [\n",
        "            f\"https://leetcode-stats-api.herokuapp.com/{username}\",\n",
        "            f\"https://alfa-leetcode-api.onrender.com/{username}/solved\",\n",
        "            f\"https://leetcode-api-faisalshohag.vercel.app/{username}\",\n",
        "            f\"https://leetcodeapi-v1.vercel.app/{username}\"\n",
        "        ]\n",
        "\n",
        "        for api_url in apis:\n",
        "            try:\n",
        "                response = self.session.get(api_url, timeout=10)\n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "\n",
        "                    # Handle different API response formats\n",
        "                    if 'totalSolved' in data:  # herokuapp format\n",
        "                        return {\n",
        "                            \"Username\": username,\n",
        "                            \"Total Problems Solved\": data.get(\"totalSolved\", 0),\n",
        "                            \"Easy\": data.get(\"easySolved\", 0),\n",
        "                            \"Medium\": data.get(\"mediumSolved\", 0),\n",
        "                            \"Hard\": data.get(\"hardSolved\", 0),\n",
        "                            \"Contest Rating\": data.get(\"contestRating\", 0),\n",
        "                            \"Contests Attended\": data.get(\"contestAttend\", 0),\n",
        "                            \"Global Ranking\": data.get(\"ranking\", 'N/A'),\n",
        "                            \"Status\": f\"Success (API: {api_url.split('/')[2]})\"\n",
        "                        }\n",
        "                    elif 'solvedProblem' in data:  # alfa-leetcode format\n",
        "                        return {\n",
        "                            \"Username\": username,\n",
        "                            \"Total Problems Solved\": data.get(\"solvedProblem\", 0),\n",
        "                            \"Easy\": data.get(\"easySolved\", 0),\n",
        "                            \"Medium\": data.get(\"mediumSolved\", 0),\n",
        "                            \"Hard\": data.get(\"hardSolved\", 0),\n",
        "                            \"Contest Rating\": data.get(\"contestRating\", 0),\n",
        "                            \"Contests Attended\": data.get(\"contestParticipation\", 0),\n",
        "                            \"Global Ranking\": 'N/A',\n",
        "                            \"Status\": f\"Success (API: {api_url.split('/')[2]})\"\n",
        "                        }\n",
        "            except Exception as e:\n",
        "                print(f\"API {api_url} failed for {username}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    def scrape_profile(self, url):\n",
        "        \"\"\"Main scraping method that tries all approaches\"\"\"\n",
        "        username = url.strip(\"/\").split(\"/\")[-1]\n",
        "        print(f\"Scraping: {username}\")\n",
        "\n",
        "        # Method 1: Try GraphQL (most reliable for contest data)\n",
        "        result = self.scrape_with_graphql(username)\n",
        "        if result and result[\"Total Problems Solved\"] > 0:\n",
        "            return result\n",
        "\n",
        "        # Method 2: Try multiple third-party APIs\n",
        "        result = self.try_multiple_apis(username)\n",
        "        if result and result[\"Total Problems Solved\"] > 0:\n",
        "            return result\n",
        "\n",
        "        # Method 3: Direct HTML scraping\n",
        "        result = self.scrape_direct_html(username, url)\n",
        "        if result and result[\"Total Problems Solved\"] > 0:\n",
        "            return result\n",
        "\n",
        "        # If all methods fail\n",
        "        return {\n",
        "            \"Username\": username,\n",
        "            \"Total Problems Solved\": \"Failed\",\n",
        "            \"Easy\": \"Failed\",\n",
        "            \"Medium\": \"Failed\",\n",
        "            \"Hard\": \"Failed\",\n",
        "            \"Contest Rating\": \"Failed\",\n",
        "            \"Contests Attended\": \"Failed\",\n",
        "            \"Global Ranking\": \"Failed\",\n",
        "            \"Status\": \"All methods failed\"\n",
        "        }\n",
        "\n",
        "def scrape_all_profiles(profiles):\n",
        "    \"\"\"Scrape all profiles with progress tracking\"\"\"\n",
        "    scraper = LeetCodeScraper()\n",
        "    data = []\n",
        "    total = len(profiles)\n",
        "\n",
        "    for i, url in enumerate(profiles, 1):\n",
        "        print(f\"\\n--- Processing {i}/{total} ---\")\n",
        "        result = scraper.scrape_profile(url)\n",
        "        data.append(result)\n",
        "\n",
        "        # Show current result\n",
        "        print(f\"Result: {result['Status']}\")\n",
        "        if result[\"Total Problems Solved\"] != \"Failed\":\n",
        "            print(f\"  Total: {result['Total Problems Solved']}, Contest Rating: {result['Contest Rating']}\")\n",
        "\n",
        "        # Rate limiting\n",
        "        time.sleep(2)  # 2 second delay between requests\n",
        "\n",
        "        # Progress checkpoint\n",
        "        if i % 10 == 0:\n",
        "            print(f\"\\n=== Checkpoint: {i}/{total} completed ===\")\n",
        "            successful = sum(1 for r in data if r['Status'] != 'All methods failed')\n",
        "            print(f\"Success rate so far: {successful/i*100:.1f}%\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def export_to_pdf(df, filename=\"leetcode_report.pdf\"):\n",
        "    \"\"\"Export DataFrame to PDF with improved formatting\"\"\"\n",
        "    doc = SimpleDocTemplate(filename, pagesize=A4)\n",
        "    elements = []\n",
        "    styles = getSampleStyleSheet()\n",
        "\n",
        "    # Title\n",
        "    elements.append(Paragraph(\"LeetCode Comprehensive Leaderboard Report\", styles['Title']))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    # Summary statistics\n",
        "    total_users = len(df)\n",
        "    successful_scrapes = len(df[df['Status'].str.contains('Success', na=False)])\n",
        "    failed_scrapes = len(df[df['Status'].str.contains('Failed', na=False)])\n",
        "\n",
        "    # Calculate averages for successful scrapes\n",
        "    numeric_df = df[df['Status'].str.contains('Success', na=False)].copy()\n",
        "    for col in ['Total Problems Solved', 'Easy', 'Medium', 'Hard', 'Contest Rating', 'Contests Attended']:\n",
        "        numeric_df[col] = pd.to_numeric(numeric_df[col], errors='coerce')\n",
        "\n",
        "    avg_total = numeric_df['Total Problems Solved'].mean() if len(numeric_df) > 0 else 0\n",
        "    avg_rating = numeric_df['Contest Rating'].mean() if len(numeric_df) > 0 else 0\n",
        "\n",
        "    summary_text = f\"\"\"\n",
        "    <b>Comprehensive Scraping Summary:</b><br/>\n",
        "    Total Users: {total_users}<br/>\n",
        "    Successfully Scraped: {successful_scrapes}<br/>\n",
        "    Failed Scrapes: {failed_scrapes}<br/>\n",
        "    Success Rate: {successful_scrapes/total_users*100:.1f}%<br/><br/>\n",
        "\n",
        "    <b>Performance Averages (Successful scrapes only):</b><br/>\n",
        "    Average Problems Solved: {avg_total:.1f}<br/>\n",
        "    Average Contest Rating: {avg_rating:.1f}<br/>\n",
        "    \"\"\"\n",
        "    elements.append(Paragraph(summary_text, styles['Normal']))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    # Create table without Status column for cleaner output\n",
        "    display_df = df.drop(['Status'], axis=1, errors='ignore')\n",
        "    table_data = [display_df.columns.tolist()] + display_df.values.tolist()\n",
        "\n",
        "    table = Table(table_data, repeatRows=1)\n",
        "    table.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.darkblue),\n",
        "        (\"TEXTCOLOR\",(0,0),(-1,0),colors.whitesmoke),\n",
        "        (\"ALIGN\",(0,0),(-1,-1),\"CENTER\"),\n",
        "        (\"GRID\", (0,0), (-1,-1), 0.5, colors.black),\n",
        "        (\"FONTSIZE\", (0,0), (-1,-1), 6),\n",
        "        (\"VALIGN\", (0,0), (-1,-1), \"MIDDLE\"),\n",
        "        # Alternate row colors\n",
        "        (\"BACKGROUND\", (0,1), (-1,-1), colors.lightgrey),\n",
        "    ]))\n",
        "\n",
        "    elements.append(table)\n",
        "    doc.build(elements)\n",
        "\n",
        "# Main execution\n",
        "print(\"ðŸš€ Starting Comprehensive LeetCode Profile Scraping...\")\n",
        "print(\"This will try GraphQL, multiple APIs, and HTML scraping for maximum success rate!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Collect all profiles\n",
        "data = scrape_all_profiles(leetcode_profiles)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Detailed summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š FINAL SCRAPING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total profiles processed: {len(df)}\")\n",
        "\n",
        "# Status breakdown\n",
        "status_counts = df['Status'].value_counts()\n",
        "print(\"\\nDetailed status breakdown:\")\n",
        "for status, count in status_counts.items():\n",
        "    print(f\"  {status}: {count}\")\n",
        "\n",
        "# Success analysis\n",
        "successful_df = df[df['Status'].str.contains('Success', na=False)]\n",
        "if len(successful_df) > 0:\n",
        "    print(f\"\\nâœ… Successfully scraped {len(successful_df)} profiles!\")\n",
        "    print(\"\\nTop performers (by total problems solved):\")\n",
        "    try:\n",
        "        numeric_df = successful_df.copy()\n",
        "        numeric_df['Total Problems Solved'] = pd.to_numeric(numeric_df['Total Problems Solved'], errors='coerce')\n",
        "        top_5 = numeric_df.nlargest(5, 'Total Problems Solved')[['Username', 'Total Problems Solved', 'Contest Rating']]\n",
        "        print(top_5.to_string(index=False))\n",
        "    except:\n",
        "        print(\"Could not calculate top performers\")\n",
        "\n",
        "# Save comprehensive data\n",
        "df.to_csv('leetcode_comprehensive_data.csv', index=False)\n",
        "print(f\"\\nðŸ’¾ Comprehensive data saved to: leetcode_comprehensive_data.csv\")\n",
        "\n",
        "# Export to PDF\n",
        "export_to_pdf(df)\n",
        "print(\"ðŸ“„ PDF report generated: leetcode_report.pdf\")\n",
        "\n",
        "# Download files\n",
        "files.download(\"leetcode_report.pdf\")\n",
        "files.download(\"leetcode_comprehensive_data.csv\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ Comprehensive scraping completed!\")\n",
        "print(\"Check the CSV file for detailed status information on each profile.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UzEEsypJd_9S",
        "outputId": "9e3659b0-5cb4-4df9-8e8f-87ed7fae9553"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "ðŸš€ Starting Comprehensive LeetCode Profile Scraping...\n",
            "This will try GraphQL, multiple APIs, and HTML scraping for maximum success rate!\n",
            "============================================================\n",
            "\n",
            "--- Processing 1/65 ---\n",
            "Scraping: Divyansh_Joshi_MNIT\n",
            "Result: Success (GraphQL)\n",
            "  Total: 675, Contest Rating: 1606.4108077259166\n",
            "\n",
            "--- Processing 2/65 ---\n",
            "Scraping: Dhruv_parashar673\n",
            "Result: Success (GraphQL)\n",
            "  Total: 395, Contest Rating: 1519.1110157268558\n",
            "\n",
            "--- Processing 3/65 ---\n",
            "Scraping: shivansh_codes\n",
            "Result: Success (GraphQL)\n",
            "  Total: 233, Contest Rating: 0\n",
            "\n",
            "--- Processing 4/65 ---\n",
            "Scraping: hardik7427\n",
            "Result: Success (GraphQL)\n",
            "  Total: 413, Contest Rating: 1650.31219552124\n",
            "\n",
            "--- Processing 5/65 ---\n",
            "Scraping: Nayu_1501\n",
            "Result: Success (GraphQL)\n",
            "  Total: 143, Contest Rating: 1456.775544607062\n",
            "\n",
            "--- Processing 6/65 ---\n",
            "Scraping: mayank_kumar123\n",
            "Result: Success (GraphQL)\n",
            "  Total: 293, Contest Rating: 1452.581008814911\n",
            "\n",
            "--- Processing 7/65 ---\n",
            "Scraping: tushardhakad355\n",
            "Result: Success (GraphQL)\n",
            "  Total: 244, Contest Rating: 1347.9539414479702\n",
            "\n",
            "--- Processing 8/65 ---\n",
            "Scraping: rajatkhedar123\n",
            "Result: Success (GraphQL)\n",
            "  Total: 272, Contest Rating: 1512.1307036115472\n",
            "\n",
            "--- Processing 9/65 ---\n",
            "Scraping: Dishank_Jha\n",
            "Result: Success (GraphQL)\n",
            "  Total: 311, Contest Rating: 1486.627378918677\n",
            "\n",
            "--- Processing 10/65 ---\n",
            "Scraping: Khushal_Saini\n",
            "Result: Success (GraphQL)\n",
            "  Total: 531, Contest Rating: 1544.314836200915\n",
            "\n",
            "=== Checkpoint: 10/65 completed ===\n",
            "Success rate so far: 100.0%\n",
            "\n",
            "--- Processing 11/65 ---\n",
            "Scraping: mauliksidana09\n",
            "Result: Success (GraphQL)\n",
            "  Total: 552, Contest Rating: 1552.6498499659526\n",
            "\n",
            "--- Processing 12/65 ---\n",
            "Scraping: rudra_singh_07\n",
            "Result: Success (GraphQL)\n",
            "  Total: 229, Contest Rating: 1341.8752813612946\n",
            "\n",
            "--- Processing 13/65 ---\n",
            "Scraping: govindsingh_777\n",
            "Result: Success (GraphQL)\n",
            "  Total: 41, Contest Rating: 0\n",
            "\n",
            "--- Processing 14/65 ---\n",
            "Scraping: Vinay-Gupta\n",
            "Result: Success (GraphQL)\n",
            "  Total: 469, Contest Rating: 1564.0015329297378\n",
            "\n",
            "--- Processing 15/65 ---\n",
            "Scraping: Shivam_goyal_\n",
            "Result: Success (GraphQL)\n",
            "  Total: 131, Contest Rating: 1581.1634182883595\n",
            "\n",
            "--- Processing 16/65 ---\n",
            "Scraping: padmesh_0150\n",
            "Result: Success (GraphQL)\n",
            "  Total: 366, Contest Rating: 1431.936264038086\n",
            "\n",
            "--- Processing 17/65 ---\n",
            "Scraping: Gaurav_1810\n",
            "Result: All methods failed\n",
            "\n",
            "--- Processing 18/65 ---\n",
            "Scraping: likhitd\n",
            "Result: All methods failed\n",
            "\n",
            "--- Processing 19/65 ---\n",
            "Scraping: Divyanshverma15\n",
            "Result: Success (GraphQL)\n",
            "  Total: 181, Contest Rating: 0\n",
            "\n",
            "--- Processing 20/65 ---\n",
            "Scraping: kushagras_94\n",
            "Result: Success (GraphQL)\n",
            "  Total: 14, Contest Rating: 0\n",
            "\n",
            "=== Checkpoint: 20/65 completed ===\n",
            "Success rate so far: 90.0%\n",
            "\n",
            "--- Processing 21/65 ---\n",
            "Scraping: harshit3458\n",
            "Result: Success (GraphQL)\n",
            "  Total: 599, Contest Rating: 1555.1990145499692\n",
            "\n",
            "--- Processing 22/65 ---\n",
            "Scraping: RachitMittal1634\n",
            "Result: Success (GraphQL)\n",
            "  Total: 704, Contest Rating: 1699.2673803736782\n",
            "\n",
            "--- Processing 23/65 ---\n",
            "Scraping: saurabh_32\n",
            "Result: Success (GraphQL)\n",
            "  Total: 660, Contest Rating: 0\n",
            "\n",
            "--- Processing 24/65 ---\n",
            "Scraping: tehseen1639\n",
            "Result: Success (GraphQL)\n",
            "  Total: 339, Contest Rating: 1378.626247728309\n",
            "\n",
            "--- Processing 25/65 ---\n",
            "Scraping: ruchika_yadav\n",
            "Result: Success (GraphQL)\n",
            "  Total: 275, Contest Rating: 1522.876\n",
            "\n",
            "--- Processing 26/65 ---\n",
            "Scraping: yugsarda\n",
            "Result: Success (GraphQL)\n",
            "  Total: 615, Contest Rating: 1385.4071969012994\n",
            "\n",
            "--- Processing 27/65 ---\n",
            "Scraping: Kartik_Mahnot\n",
            "Result: Success (GraphQL)\n",
            "  Total: 579, Contest Rating: 1583.6453541125381\n",
            "\n",
            "--- Processing 28/65 ---\n",
            "Scraping: ViNiT-72\n",
            "Result: Success (GraphQL)\n",
            "  Total: 294, Contest Rating: 0\n",
            "\n",
            "--- Processing 29/65 ---\n",
            "Scraping: RK_Patel\n",
            "Result: Success (GraphQL)\n",
            "  Total: 1147, Contest Rating: 2039.9135632571758\n",
            "\n",
            "--- Processing 30/65 ---\n",
            "Scraping: beingKashvi\n",
            "Result: All methods failed\n",
            "\n",
            "=== Checkpoint: 30/65 completed ===\n",
            "Success rate so far: 90.0%\n",
            "\n",
            "--- Processing 31/65 ---\n",
            "Scraping: vikas_singh_856\n",
            "Result: Success (GraphQL)\n",
            "  Total: 465, Contest Rating: 1786.9131462158252\n",
            "\n",
            "--- Processing 32/65 ---\n",
            "Scraping: user2633T\n",
            "Result: Success (GraphQL)\n",
            "  Total: 269, Contest Rating: 1393.336061731491\n",
            "\n",
            "--- Processing 33/65 ---\n",
            "Scraping: ShourayaKaushik\n",
            "Result: Success (GraphQL)\n",
            "  Total: 110, Contest Rating: 0\n",
            "\n",
            "--- Processing 34/65 ---\n",
            "Scraping: jatin-agrawal\n",
            "Result: Success (GraphQL)\n",
            "  Total: 771, Contest Rating: 1622.9624352589017\n",
            "\n",
            "--- Processing 35/65 ---\n",
            "Scraping: Bot-Netizen-Programmers\n",
            "Result: Success (GraphQL)\n",
            "  Total: 3, Contest Rating: 0\n",
            "\n",
            "--- Processing 36/65 ---\n",
            "Scraping: bhargav-1673\n",
            "Result: Success (GraphQL)\n",
            "  Total: 53, Contest Rating: 0\n",
            "\n",
            "--- Processing 37/65 ---\n",
            "Scraping: Lakshit_Ramani\n",
            "Result: Success (GraphQL)\n",
            "  Total: 377, Contest Rating: 1413.731575012207\n",
            "\n",
            "--- Processing 38/65 ---\n",
            "Scraping: dhakad_09\n",
            "Result: Success (GraphQL)\n",
            "  Total: 734, Contest Rating: 1666.1319479342194\n",
            "\n",
            "--- Processing 39/65 ---\n",
            "Scraping: NAregarded\n",
            "Result: All methods failed\n",
            "\n",
            "--- Processing 40/65 ---\n",
            "Scraping: akshaypal_bishnoi\n",
            "Result: Success (GraphQL)\n",
            "  Total: 237, Contest Rating: 1460.0191046443483\n",
            "\n",
            "=== Checkpoint: 40/65 completed ===\n",
            "Success rate so far: 90.0%\n",
            "\n",
            "--- Processing 41/65 ---\n",
            "Scraping: godika_priya\n",
            "Result: All methods failed\n",
            "\n",
            "--- Processing 42/65 ---\n",
            "Scraping: Tush1586\n",
            "Result: Success (GraphQL)\n",
            "  Total: 375, Contest Rating: 1524.71923828125\n",
            "\n",
            "--- Processing 43/65 ---\n",
            "Scraping: Sarvesh25\n",
            "Result: Success (GraphQL)\n",
            "  Total: 472, Contest Rating: 1481.4829346318322\n",
            "\n",
            "--- Processing 44/65 ---\n",
            "Scraping: user8201yw\n",
            "Result: Success (GraphQL)\n",
            "  Total: 298, Contest Rating: 1412.485299115005\n",
            "\n",
            "--- Processing 45/65 ---\n",
            "Scraping: Swayam_141\n",
            "Result: Success (GraphQL)\n",
            "  Total: 162, Contest Rating: 1592.259407043457\n",
            "\n",
            "--- Processing 46/65 ---\n",
            "Scraping: Kashishgarg_15\n",
            "Result: Success (GraphQL)\n",
            "  Total: 440, Contest Rating: 1411.487\n",
            "\n",
            "--- Processing 47/65 ---\n",
            "Scraping: princimantri_2990\n",
            "Result: Success (GraphQL)\n",
            "  Total: 520, Contest Rating: 1589.461326599121\n",
            "\n",
            "--- Processing 48/65 ---\n",
            "Scraping: ankit4092004_Ankit___\n",
            "Result: All methods failed\n",
            "\n",
            "--- Processing 49/65 ---\n",
            "Scraping: pritamzzziscodingpranav_1686\n",
            "Result: All methods failed\n",
            "\n",
            "--- Processing 50/65 ---\n",
            "Scraping: Dhruvik_MYI\n",
            "Result: Success (GraphQL)\n",
            "  Total: 775, Contest Rating: 1455.6879200375206\n",
            "\n",
            "=== Checkpoint: 50/65 completed ===\n",
            "Success rate so far: 86.0%\n",
            "\n",
            "--- Processing 51/65 ---\n",
            "Scraping: pankaj1213\n",
            "Result: Success (GraphQL)\n",
            "  Total: 251, Contest Rating: 1465.042338506708\n",
            "\n",
            "--- Processing 52/65 ---\n",
            "Scraping: kavya1502_\n",
            "Result: Success (GraphQL)\n",
            "  Total: 490, Contest Rating: 1608.8863172029194\n",
            "\n",
            "--- Processing 53/65 ---\n",
            "Scraping: suhaani17\n",
            "Result: Success (GraphQL)\n",
            "  Total: 197, Contest Rating: 1459.0292478862561\n",
            "\n",
            "--- Processing 54/65 ---\n",
            "Scraping: Dikshit_Rao\n",
            "Result: Success (GraphQL)\n",
            "  Total: 199, Contest Rating: 1548.508644104004\n",
            "\n",
            "--- Processing 55/65 ---\n",
            "Scraping: krishnasharma1234\n",
            "Result: Success (GraphQL)\n",
            "  Total: 501, Contest Rating: 1490.6314558499446\n",
            "\n",
            "--- Processing 56/65 ---\n",
            "Scraping: KRITI_BHATNAGAR\n",
            "Result: Success (GraphQL)\n",
            "  Total: 599, Contest Rating: 1676.8496517542872\n",
            "\n",
            "--- Processing 57/65 ---\n",
            "Scraping: Roshan_nama12\n",
            "Result: Success (GraphQL)\n",
            "  Total: 35, Contest Rating: 0\n",
            "\n",
            "--- Processing 58/65 ---\n",
            "Scraping: gautam_chauhan04\n",
            "Result: Success (GraphQL)\n",
            "  Total: 81, Contest Rating: 1438.3353183144018\n",
            "\n",
            "--- Processing 59/65 ---\n",
            "Scraping: ayushkumar85371\n",
            "Result: Success (GraphQL)\n",
            "  Total: 296, Contest Rating: 1293.9775313282935\n",
            "\n",
            "--- Processing 60/65 ---\n",
            "Scraping: Gulab_Rana\n",
            "Result: Success (GraphQL)\n",
            "  Total: 42, Contest Rating: 0\n",
            "\n",
            "=== Checkpoint: 60/65 completed ===\n",
            "Success rate so far: 88.3%\n",
            "\n",
            "--- Processing 61/65 ---\n",
            "Scraping: utkarshmodi10\n",
            "Result: Success (GraphQL)\n",
            "  Total: 19, Contest Rating: 0\n",
            "\n",
            "--- Processing 62/65 ---\n",
            "Scraping: Yash_07___077\n",
            "Result: Success (GraphQL)\n",
            "  Total: 209, Contest Rating: 1373.7017580141508\n",
            "\n",
            "--- Processing 63/65 ---\n",
            "Scraping: MJ_Champ\n",
            "Result: Success (GraphQL)\n",
            "  Total: 800, Contest Rating: 1813.3601248854955\n",
            "\n",
            "--- Processing 64/65 ---\n",
            "Scraping: AyushTak\n",
            "Result: Success (GraphQL)\n",
            "  Total: 144, Contest Rating: 0\n",
            "\n",
            "--- Processing 65/65 ---\n",
            "Scraping: SIY7gDUBSu\n",
            "Result: All methods failed\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š FINAL SCRAPING SUMMARY\n",
            "============================================================\n",
            "Total profiles processed: 65\n",
            "\n",
            "Detailed status breakdown:\n",
            "  Success (GraphQL): 57\n",
            "  All methods failed: 8\n",
            "\n",
            "âœ… Successfully scraped 57 profiles!\n",
            "\n",
            "Top performers (by total problems solved):\n",
            "     Username  Total Problems Solved Contest Rating\n",
            "     RK_Patel                   1147    2039.913563\n",
            "     MJ_Champ                    800    1813.360125\n",
            "  Dhruvik_MYI                    775     1455.68792\n",
            "jatin-agrawal                    771    1622.962435\n",
            "    dhakad_09                    734    1666.131948\n",
            "\n",
            "ðŸ’¾ Comprehensive data saved to: leetcode_comprehensive_data.csv\n",
            "ðŸ“„ PDF report generated: leetcode_report.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_afb3e14c-01b4-4ead-8ce6-6e4664e8e0e0\", \"leetcode_report.pdf\", 9087)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_43654b6f-54e9-450e-b398-6ad773a456de\", \"leetcode_comprehensive_data.csv\", 4660)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ‰ Comprehensive scraping completed!\n",
            "Check the CSV file for detailed status information on each profile.\n"
          ]
        }
      ]
    }
  ]
}